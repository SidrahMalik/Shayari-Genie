{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9594522-b43c-4a09-adc8-3a55d03709dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text (First 500 chars):\n",
      " ID Poet Poetry\n",
      "1ahmad-faraz aaÃ±kh  se duur na ho dil se utar jÄ.egÄ\n",
      "vaqt kÄ kyÄ hai guzartÄ  hai guzar  jÄ.egÄ\n",
      "itnÄ mÄnÅ«s  na ho á¸³halvat-e-Ä¡ham  se apnÄ«\n",
      "tÅ« kabhÄ«  á¸³hud  ko bhÄ« dekhegÄ  to Dar jÄ.egÄ\n",
      "DÅ«bte  DÅ«bte  kashtÄ«  ko uchhÄlÄ  de duuÃ±\n",
      "maiÃ±  nahÄ«Ã±  koÄ« to sÄhil pe utar jÄ.egÄ\n",
      "zindagÄ«  terÄ« atÄ hai to ye jaane  vaalÄ\n",
      "terÄ« baá¸³hshish  tirÄ« dahlÄ«z  pe dhar jÄ.egÄ\n",
      "zabt lÄzim  hai magar  dukh  hai qayÄmat  kÄ 'farÄz'\n",
      "zÄlim  ab ke bhÄ« na ro.egÄ  to mar jÄ.egÄ2ahmad-faraz ÄshiqÄ«  meÃ± 'mÄ«r' jaise á¸³h\n",
      "Sample Cleaned Text (First 500 chars):\n",
      " id poet poetry ahmadfaraz aaÃ±kh se duur na ho dil se utar jÄegÄ vaqt kÄ kyÄ hai guzartÄ hai guzar jÄegÄ itnÄ mÄnÅ«s na ho á¸³halvateÄ¡ham se apnÄ« tÅ« kabhÄ« á¸³hud ko bhÄ« dekhegÄ to dar jÄegÄ dÅ«bte dÅ«bte kashtÄ« ko uchhÄlÄ de duuÃ± maiÃ± nahÄ«Ã± koÄ« to sÄhil pe utar jÄegÄ zindagÄ« terÄ« atÄ hai to ye jaane vaalÄ terÄ« baá¸³hshish tirÄ« dahlÄ«z pe dhar jÄegÄ zabt lÄzim hai magar dukh hai qayÄmat kÄ farÄz zÄlim ab ke bhÄ« na roegÄ to mar jÄegÄahmadfaraz ÄshiqÄ« meÃ± mÄ«r jaise á¸³hvÄb mat dekhÄ karo bÄvle ho jÄoge mahtÄb m\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "\n",
    "# Load the PDF\n",
    "pdf_path = \"rekhtaData.pdf\"\n",
    "\n",
    "with open(pdf_path, \"rb\") as f:\n",
    "    reader = PyPDF2.PdfReader(f)\n",
    "    text = \" \".join([page.extract_text() for page in reader.pages if page.extract_text()])  # Extract text\n",
    "\n",
    "# Debugging Step: Print some extracted text\n",
    "print(\"Extracted Text (First 500 chars):\\n\", text[:500])  \n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r\"\\d+\", \"\", text)  # Remove numbers\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)  # Remove special characters\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # Remove extra spaces\n",
    "    return text\n",
    "\n",
    "# Cleaned text\n",
    "cleaned_text = clean_text(text)\n",
    "\n",
    "# Save cleaned data\n",
    "with open(\"cleaned_poetry.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(cleaned_text)\n",
    "\n",
    "print(\"Sample Cleaned Text (First 500 chars):\\n\", cleaned_text[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fc6cd5e-214c-4434-9193-d6f3ecc737e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Words: 18063\n",
      "Max Sequence Length: 50\n",
      "Number of Training Samples: 4999\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([cleaned_text])\n",
    "total_words = len(tokenizer.word_index) + 1  # +1 for padding token\n",
    "\n",
    "# Convert Text to Sequences\n",
    "input_sequences = []\n",
    "words = cleaned_text.split()\n",
    "\n",
    "for i in range(1, min(5000, len(words))):  # Limit to 5000 words for efficiency\n",
    "    n_gram_sequence = words[:i+1]  # Create n-grams\n",
    "    encoded = tokenizer.texts_to_sequences([\" \".join(n_gram_sequence)])[0]\n",
    "    input_sequences.append(encoded)\n",
    "\n",
    "# Reduce Max Sequence Length to 50\n",
    "max_sequence_length = min(50, max([len(seq) for seq in input_sequences]))\n",
    "\n",
    "# Padding Sequences\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding=\"pre\")\n",
    "\n",
    "# Split into Features (X) and Labels (y)\n",
    "X, y = input_sequences[:, :-1], input_sequences[:, -1]\n",
    "y = np.array(y)\n",
    "\n",
    "# Print some stats\n",
    "print(f\"Total Words: {total_words}\")\n",
    "print(f\"Max Sequence Length: {max_sequence_length}\")\n",
    "print(f\"Number of Training Samples: {len(X)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094a7b08-22e0-4058-adf8-7b6bfe3d431f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 213ms/step - accuracy: 0.0337 - loss: 8.1534\n",
      "Epoch 2/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 206ms/step - accuracy: 0.0334 - loss: 6.2434\n",
      "Epoch 3/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 218ms/step - accuracy: 0.0323 - loss: 6.0906\n",
      "Epoch 4/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 224ms/step - accuracy: 0.0362 - loss: 6.0626\n",
      "Epoch 5/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 208ms/step - accuracy: 0.0247 - loss: 5.9701\n",
      "Epoch 6/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m588s\u001b[0m 4s/step - accuracy: 0.0331 - loss: 5.9300\n",
      "Epoch 7/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 222ms/step - accuracy: 0.0359 - loss: 5.8364\n",
      "Epoch 8/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 201ms/step - accuracy: 0.0419 - loss: 5.7401\n",
      "Epoch 9/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 217ms/step - accuracy: 0.0398 - loss: 5.6842\n",
      "Epoch 10/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 215ms/step - accuracy: 0.0444 - loss: 5.5141\n",
      "Epoch 11/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 215ms/step - accuracy: 0.0503 - loss: 5.3306\n",
      "Epoch 12/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 1s/step - accuracy: 0.0550 - loss: 5.2796\n",
      "Epoch 13/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 223ms/step - accuracy: 0.0512 - loss: 5.1857\n",
      "Epoch 14/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 223ms/step - accuracy: 0.0595 - loss: 5.0326\n",
      "Epoch 15/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 210ms/step - accuracy: 0.0759 - loss: 4.8498\n",
      "Epoch 16/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 225ms/step - accuracy: 0.0858 - loss: 4.7419\n",
      "Epoch 17/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 220ms/step - accuracy: 0.1150 - loss: 4.5840\n",
      "Epoch 18/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 204ms/step - accuracy: 0.1204 - loss: 4.4079\n",
      "Epoch 19/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 216ms/step - accuracy: 0.1288 - loss: 4.2538\n",
      "Epoch 20/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 217ms/step - accuracy: 0.1527 - loss: 4.1634\n",
      "Epoch 21/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 217ms/step - accuracy: 0.1715 - loss: 3.9430\n",
      "Epoch 22/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m582s\u001b[0m 224ms/step - accuracy: 0.1910 - loss: 3.8030\n",
      "Epoch 23/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 220ms/step - accuracy: 0.2195 - loss: 3.6626\n",
      "Epoch 24/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 215ms/step - accuracy: 0.2473 - loss: 3.5289\n",
      "Epoch 25/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 204ms/step - accuracy: 0.2615 - loss: 3.4208\n",
      "Epoch 26/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 216ms/step - accuracy: 0.3046 - loss: 3.2023\n",
      "Epoch 27/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 225ms/step - accuracy: 0.3213 - loss: 3.1323\n",
      "Epoch 28/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 1s/step - accuracy: 0.3549 - loss: 2.9492\n",
      "Epoch 29/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 218ms/step - accuracy: 0.3743 - loss: 2.8734\n",
      "Epoch 30/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 215ms/step - accuracy: 0.4030 - loss: 2.6868\n",
      "Epoch 31/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 209ms/step - accuracy: 0.4345 - loss: 2.5601\n",
      "Epoch 32/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 217ms/step - accuracy: 0.4753 - loss: 2.4013\n",
      "Epoch 33/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 214ms/step - accuracy: 0.4850 - loss: 2.3292\n",
      "Epoch 34/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 767ms/step - accuracy: 0.5337 - loss: 2.1479\n",
      "Epoch 35/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 214ms/step - accuracy: 0.5486 - loss: 2.1072\n",
      "Epoch 36/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 222ms/step - accuracy: 0.5636 - loss: 1.9967\n",
      "Epoch 37/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 225ms/step - accuracy: 0.5836 - loss: 1.9273\n",
      "Epoch 38/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 230ms/step - accuracy: 0.6167 - loss: 1.8060\n",
      "Epoch 39/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 231ms/step - accuracy: 0.6335 - loss: 1.7226\n",
      "Epoch 40/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 217ms/step - accuracy: 0.6472 - loss: 1.6672\n",
      "Epoch 41/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2306s\u001b[0m 15s/step - accuracy: 0.6793 - loss: 1.5508\n",
      "Epoch 42/50\n",
      "\u001b[1m138/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m4s\u001b[0m 226ms/step - accuracy: 0.7012 - loss: 1.4539"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
    "\n",
    "# Define GRU Model\n",
    "model = Sequential([\n",
    "    Embedding(total_words, 100, input_length=max_sequence_length - 1),  # Word Embeddings\n",
    "    GRU(256, return_sequences=True),  # First GRU layer\n",
    "    GRU(256),  # Second GRU layer\n",
    "    Dense(total_words, activation=\"softmax\")  # Output layer\n",
    "])\n",
    "\n",
    "# Compile Model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the Model\n",
    "epochs = 50  # You can increase for better results\n",
    "history = model.fit(X, y, epochs=epochs, verbose=1)\n",
    "\n",
    "# Save the Model  \n",
    "model.save(\"urdu_poetry_model.h5\")\n",
    "\n",
    "print(\"ğŸ‰ Model training complete and saved as 'urdu_poetry_model.h5'!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a45fb96e-abf6-403d-a182-932f70fc8e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "aankh se door aaÃ±kh se utar jÄegÄ vaqt kÄ kyÄ hai guzartÄ ke unvÄÃ± jÄnÄÃ± duuÃ± tÅ« ne kabhÄ« á¸³hvÄhishoÃ± ko uchhÄlÄ de\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_poetry(seed_text, next_words=20, temperature=0.8):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_length - 1, padding=\"pre\")\n",
    "        \n",
    "        predictions = model.predict(token_list)[0]\n",
    "        predictions = np.log(predictions + 1e-7) / temperature  # Apply temperature scaling\n",
    "        exp_preds = np.exp(predictions)\n",
    "        probabilities = exp_preds / np.sum(exp_preds)\n",
    "\n",
    "        predicted = np.random.choice(len(probabilities), p=probabilities)  # Sample from the probability distribution\n",
    "        \n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "\n",
    "        seed_text += \" \" + output_word\n",
    "    return seed_text\n",
    "\n",
    "# Example usage\n",
    "print(generate_poetry(\"aankh se door\", next_words=20, temperature=0.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51448605-44ad-4c8a-95cc-e0ecf75af610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Using cached gradio-5.16.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\abc\\anaconda3\\lib\\site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\abc\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (4.2.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\abc\\anaconda3\\lib\\site-packages (from gradio) (0.115.8)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\abc\\anaconda3\\lib\\site-packages (from gradio) (0.5.0)\n",
      "Requirement already satisfied: gradio-client==1.7.0 in c:\\users\\abc\\anaconda3\\lib\\site-packages (from gradio) (1.7.0)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\abc\\anaconda3\\lib\\site-packages (from gradio) (0.27.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.28.1 in c:\\users\\abc\\anaconda3\\lib\\site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\abc\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (3.1.3)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\abc\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (2.1.4)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\abc\\anaconda3\\lib\\site-packages (from gradio) (1.26.4)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\abc\\anaconda3\\lib\\site-packages (from gradio) (3.10.15)\n",
      "Requirement already satisfied: packaging in c:\\users\\abc\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (23.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\abc\\anaconda3\\lib\\site-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\abc\\anaconda3\\lib\\site-packages (from gradio) (10.4.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\users\\abc\\anaconda3\\lib\\site-packages (from gradio) (2.8.2)\n",
      "Requirement already satisfied: pydub in c:\\users\\abc\\anaconda3\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\abc\\anaconda3\\lib\\site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\abc\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (6.0.1)\n",
      "Requirement already satisfied: ruff>=0.9.3 in c:\\users\\abc\\anaconda3\\lib\\site-packages (from gradio) (0.9.6)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in c:\\users\\abc\\anaconda3\\lib\\site-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\abc\\anaconda3\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\abc\\anaconda3\\lib\\site-packages (from gradio) (0.45.3)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\abc\\anaconda3\\lib\\site-packages (from gradio) (0.13.2)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\abc\\anaconda3\\lib\\site-packages (from gradio) (0.15.1)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\abc\\anaconda3\\lib\\site-packages (from gradio) (4.11.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\abc\\anaconda3\\lib\\site-packages (from gradio) (0.34.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\abc\\anaconda3\\lib\\site-packages (from gradio-client==1.7.0->gradio) (2024.6.1)\n",
      "Requirement already satisfied: websockets<15.0,>=10.0 in c:\\users\\abc\\anaconda3\\lib\\site-packages (from gradio-client==1.7.0->gradio) (14.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\abc\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\abc\\appdata\\roaming\\python\\python312\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\abc\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\abc\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\abc\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\abc\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (3.13.1)\n",
      "Requirement already satisfied: requests in c:\\users\\abc\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\abc\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (4.66.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\abc\\appdata\\roaming\\python\\python312\\site-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\abc\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\abc\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\abc\\anaconda3\\lib\\site-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\abc\\anaconda3\\lib\\site-packages (from pydantic>=2.0->gradio) (2.20.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\abc\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\abc\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\abc\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\abc\\appdata\\roaming\\python\\python312\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abc\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\abc\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\abc\\appdata\\roaming\\python\\python312\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.17.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\abc\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abc\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.2.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\abc\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.0)\n",
      "Using cached gradio-5.16.0-py3-none-any.whl (62.2 MB)\n",
      "Installing collected packages: gradio\n",
      "Successfully installed gradio-5.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6458976d-e8bd-4d65-8181-c95ca2f76e46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
